{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QVIM-AES Submission Template\n",
    "\n",
    "This is the submission template for the Query by Vocal Imitation challenge at the 2025 AES International Conference on Artificial Intelligence and Machine Learning for Audio.\n",
    "\n",
    "The content of this notebook is inspired by the template provided by the task organizers of the [Sound Scene Synthesis Taks of the DCASE Challenge 2024](https://dcase.community/challenge2024/task-sound-scene-synthesis).\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<b>Confidentiality Statement</b><br> As the organizers of this contest, we assure all participants that their submitted models and code will be treated with strict confidentiality. Submissions will only be accessed by the designated review team for evaluation purposes and will not be shared, distributed, or used beyond the scope of this challenge. Participants retain full ownership of their work. We will not claim any rights over the submitted materials, nor will we use them for any purpose outside of the challenge evaluation process. We appreciate your participation in this challenge.\n",
    "</div>\n",
    "\n",
    "#### How to create your submission\n",
    "- Get familiar with the existing code blocks and the example provided below.\n",
    "- Set the root path of your environment and your dataset below (\"TODO: DEFINE YOUR PATHS HERE.\").\n",
    "- Set up your project (\"TODO: SETUP YOUR PROJECT HERE.\").\n",
    "- Implement the retrieval interface below (\"TODO: ADD YOUR IMPLEMENTATION HERE.\").\n",
    "    - Use the provided helper functions (helpers) to download your source code, model checkpoints, etc.\n",
    "- Instantiate your retrieval model (\"TODO: INSTANTIATE YOUR MODEL HERE.\").\n",
    "- Before **submitting your notebook**, run this notebook in a clean conda environment (with python >= 3.10) on Ubuntu 24.04 and make sure the evaluation results are in line with your previous results.\n",
    "- Submit your notebooks and the technical report as described on our [website](https://qvim-aes.github.io/).\n",
    "\n",
    "##### Some Rules\n",
    "- DO NOT modify the other code cells.\n",
    "- DO NOT add new cells.\n",
    "- Store your project WITHIN 'ROOT_PATH' and your data within 'DATA_PATH'.\n",
    "- DO NOT use 'ROOT_PATH/output' folder; this is where we will store things.\n",
    "- DO NOT change the working directory (e.g., `os.chdir('/path/to/a/dir/that/does/not/exist/on/my/machine')`).\n",
    "- DO NOT use system commands (`!cd ~` or `os.system('cd ~')`, etc.) other than the ones used to set up your environment (i.e., install required packages with pip, conda, ...).\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"> \n",
    "Participant who submit malicious code will be disqualified.\n",
    "</div>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting GitPython\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting gdown==5.1.0\n",
      "  Downloading gdown-5.1.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from gdown==5.1.0) (4.12.3)\n",
      "Collecting filelock (from gdown==5.1.0)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests[socks] in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from gdown==5.1.0) (2.32.3)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Downloading numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting scipy>=1.6.0 (from librosa)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting scikit-learn>=1.1.0 (from librosa)\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting joblib>=1.0 (from librosa)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from librosa) (5.1.1)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-0.5.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from librosa) (4.12.2)\n",
      "Collecting lazy_loader>=0.1 (from librosa)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Downloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from pooch>=1.1->librosa) (4.3.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from requests[socks]->gdown==5.1.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from requests[socks]->gdown==5.1.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from requests[socks]->gdown==5.1.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from requests[socks]->gdown==5.1.0) (2025.4.26)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.1.0->librosa)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from beautifulsoup4->gdown==5.1.0) (2.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from requests[socks]->gdown==5.1.0) (1.7.1)\n",
      "Downloading gdown-5.1.0-py3-none-any.whl (17 kB)\n",
      "Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m249.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m250.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
      "Downloading numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m198.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m173.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m174.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m181.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m129.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soxr-0.5.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (252 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: pytz, tzdata, tqdm, threadpoolctl, smmap, numpy, msgpack, llvmlite, lazy_loader, joblib, filelock, audioread, soxr, soundfile, scipy, pooch, pandas, numba, gitdb, scikit-learn, GitPython, gdown, librosa\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/23\u001b[0m [librosa]0/23\u001b[0m [GitPython]rn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed GitPython-3.1.44 audioread-3.0.1 filelock-3.18.0 gdown-5.1.0 gitdb-4.0.12 joblib-1.5.1 lazy_loader-0.4 librosa-0.11.0 llvmlite-0.44.0 msgpack-1.1.0 numba-0.61.2 numpy-2.2.6 pandas-2.2.3 pooch-1.8.2 pytz-2025.2 scikit-learn-1.6.1 scipy-1.15.3 smmap-5.0.2 soundfile-0.13.1 soxr-0.5.0.post1 threadpoolctl-3.6.0 tqdm-4.67.1 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DO NOT MODIFY THIS BLOCK.\n",
    "\"\"\"\n",
    "# Install basic packages for template notebook.\n",
    "!pip install librosa numpy pandas tqdm GitPython gdown==5.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DO NOT MODIFY THIS BLOCK.\n",
    "\"\"\"\n",
    "# some imports\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNASsBThlM2s"
   },
   "source": [
    "## Description of the Retrieval Interface \n",
    "`QVIMModel` is the interface specification for all query by vocal imitation systems. Each submitted system is expected to subclass this interface and implement the `compute_similarities` method, which computes the similarities between all pairwise combinations of queries (vocal imitations) and items (reference sounds).\n",
    "\n",
    "`compute_similarities` takes two dictionaries as input:\n",
    "- queries is a dictionary mapping ids of items to be retrieved to the corresponding file paths.\n",
    "- items is a dictionary mapping query ids to the corresponding file paths\n",
    "\n",
    "Participants are expected to load the sounds themselves, e.g., with `librosa.load`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "008R-IAWX0C5"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DO NOT MODIFY THIS BLOCK.\n",
    "\"\"\"\n",
    "\n",
    "class QVIMModel(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def compute_similarities(\n",
    "            self, items: dict[str, str], queries: dict[str, str]\n",
    "    ) -> dict[str, dict[str, float]]:\n",
    "        \"\"\"Compute similarity scores between items to be retrieved and a set of queries.\n",
    "\n",
    "        Each <query, item> pairing should be assigned a single floating point score, where higher\n",
    "        scores indicate higher similarity.\n",
    "\n",
    "        Args:\n",
    "            items (dict[str, str]): A dictionary mapping ids of items to be retrieved to the corresponding file path\n",
    "            queries (dict[str, str]): A dictionary mapping query ids to the corresponding file path\n",
    "\n",
    "        Returns:\n",
    "            scores (dict[str, dict[str, float]]): A dictionary mapping query ids to a dictionary of item\n",
    "                ids and their corresponding similarity scores. E.g:\n",
    "                {\n",
    "                    \"query_1\": {\n",
    "                        \"item_1\": 0.8,\n",
    "                        \"item_2\": 0.6,\n",
    "                        ...\n",
    "                    },\n",
    "                    \"query_2\": {\n",
    "                        \"item_1\": 0.4,\n",
    "                        \"item_2\": 0.9,\n",
    "                        ...\n",
    "                    },\n",
    "                    ...\n",
    "                }\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVKQD14BnoSd"
   },
   "source": [
    "## Some Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`helpers.py` contains some helpful functions for downloading code and model checkpoints from Google Drive, Git and public links.\n",
    "\n",
    "The functions were taken (with slight modifications) from the submission template provided by the task organizers of [Task 7 of the DCASE Challenge 2024: Sound Scene Synthesis](https://dcase.community/challenge2024/task-sound-scene-synthesis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T01:07:57.902769Z",
     "start_time": "2025-04-05T01:07:57.799703Z"
    }
   },
   "outputs": [],
   "source": [
    "import helpers\n",
    "from helpers import google_drive_download, wget_download, git_clone_checkout, unpack_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup your paths\n",
    "\n",
    "- Define `ROOT_PATH`; this is where your project lives; for testing, we'll replace it with our custom ROOT_PATH. We recommend using the current working directory ('.').\n",
    "- Define `DATA_PATH`; this is where your public development data lives; for testing, we'll replace it with our custom DATA_PATH. We recommend using 'data/qvim-dev'.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T01:07:57.910317Z",
     "start_time": "2025-04-05T01:07:57.908291Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: DEFINE YOUR PATHS HERE.\n",
    "\"\"\"\n",
    "\n",
    "# replace this with your custom ROOT_PATH; this is where your code/ checkpoints will be downloaded to\n",
    "ROOT_PATH = \".\"\n",
    "\n",
    "# path to the evaluation data; can be in ROOT_PATH\n",
    "DATA_PATH = os.path.join(ROOT_PATH, \"DEVUpdatedDataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T01:07:57.962831Z",
     "start_time": "2025-04-05T01:07:57.959787Z"
    }
   },
   "outputs": [],
   "source": [
    "helpers.ROOT_PATH = ROOT_PATH\n",
    "os.makedirs(ROOT_PATH, exist_ok=True)\n",
    "os.makedirs(DATA_PATH, exist_ok=True)\n",
    "sys.path.append(os.path.join(ROOT_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Setup your environment, download checkpoints, etc.\n",
    "\n",
    "Setup your project and install the required packages here.\n",
    "The easiest way is to:\n",
    "1) convert your implementation into a package,\n",
    "2) clone the repository and checkout the specific branch and commit,\n",
    "3) install your package with pip install -e name_of_your_fancy_package\n",
    "\n",
    "\n",
    "Hints:\n",
    "- Make sure your link to the repository and other URLs are publicly available.\n",
    "- Use **shared public URLs** (e.g. a shared Google Drive, Dropbox, Zenodo link) to download checkpoints into `ROOT_PATH`.\n",
    "- Use the provided helper functions (`google_drive_download`, `wget_download`, `git_clone_checkout`, and `unpack_file`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2FA2V1lYC3fy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository cloned to ./qvim_baseline_rp and checked out to main at commit 8222f2f4651b08a7d3a47026bce6948657c7bf2e.\n",
      "Cloned RP335/qvim-baseline repository.\n",
      "Collecting speechbrain\n",
      "  Downloading speechbrain-1.0.3-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting hear21passt\n",
      "  Downloading hear21passt-0.0.26-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting panns_inference\n",
      "  Downloading panns_inference-0.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.19.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting torchaudio==2.6.0\n",
      "  Downloading torchaudio-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting torch==2.6.0\n",
      "  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting lightning==2.5.1\n",
      "  Downloading lightning-2.5.1-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: librosa==0.11.0 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (0.11.0)\n",
      "Collecting torchvision==0.21.0\n",
      "  Downloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from torch==2.6.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from torch==2.6.0) (4.12.2)\n",
      "Collecting networkx (from torch==2.6.0)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from torch==2.6.0) (3.1.6)\n",
      "Collecting fsspec (from torch==2.6.0)\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.6.0)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.6.0)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch==2.6.0)\n",
      "  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting sympy==1.13.1 (from torch==2.6.0)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from lightning==2.5.1) (6.0.2)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning==2.5.1)\n",
      "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from lightning==2.5.1) (24.2)\n",
      "Collecting torchmetrics<3.0,>=0.7.0 (from lightning==2.5.1)\n",
      "  Downloading torchmetrics-1.7.2-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from lightning==2.5.1) (4.67.1)\n",
      "Collecting pytorch-lightning (from lightning==2.5.1)\n",
      "  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from librosa==0.11.0) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from librosa==0.11.0) (0.61.2)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from librosa==0.11.0) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from librosa==0.11.0) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from librosa==0.11.0) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from librosa==0.11.0) (1.5.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from librosa==0.11.0) (5.1.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from librosa==0.11.0) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from librosa==0.11.0) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from librosa==0.11.0) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from librosa==0.11.0) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from librosa==0.11.0) (1.1.0)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.21.0)\n",
      "  Downloading pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.6.0)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1)\n",
      "  Downloading aiohttp-3.12.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning==2.5.1) (78.1.1)\n",
      "Collecting hyperpyyaml (from speechbrain)\n",
      "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting sentencepiece (from speechbrain)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting huggingface_hub (from speechbrain)\n",
      "  Downloading huggingface_hub-0.32.3-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting timm>=0.4.12 (from hear21passt)\n",
      "  Downloading timm-1.0.15-py3-none-any.whl.metadata (52 kB)\n",
      "Collecting matplotlib (from panns_inference)\n",
      "  Downloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting torchlibrosa (from panns_inference)\n",
      "  Downloading torchlibrosa-0.1.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting click!=8.0.0,>=7.1 (from wandb)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from wandb) (4.3.7)\n",
      "Collecting protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 (from wandb)\n",
      "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from wandb) (5.9.0)\n",
      "Collecting pydantic<3 (from wandb)\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from wandb) (2.32.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-2.29.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.6-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3->wandb)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3->wandb)\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3->wandb)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1) (24.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1)\n",
      "  Downloading frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1)\n",
      "  Downloading multidict-6.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1)\n",
      "  Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1)\n",
      "  Downloading yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from numba>=0.51.0->librosa==0.11.0) (0.44.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from scikit-learn>=1.1.0->librosa==0.11.0) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa==0.11.0) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa==0.11.0) (2.21)\n",
      "Collecting safetensors (from timm>=0.4.12->hear21passt)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface_hub->speechbrain)\n",
      "  Downloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain)\n",
      "  Downloading ruamel.yaml-0.18.12-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain)\n",
      "  Downloading ruamel.yaml.clib-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from jinja2->torch==2.6.0) (3.0.2)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->panns_inference)\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->panns_inference)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->panns_inference)\n",
      "  Downloading fonttools-4.58.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (106 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->panns_inference)\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->panns_inference)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/miniconda3/envs/qvim-submission/lib/python3.10/site-packages (from matplotlib->panns_inference) (2.9.0.post0)\n",
      "Downloading torchaudio-2.6.0-cp310-cp310-manylinux1_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m155.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading lightning-2.5.1-py3-none-any.whl (818 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m818.9/818.9 kB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m148.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m209.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m143.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m136.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m140.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m130.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m130.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m132.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m131.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m159.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m185.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m118.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.7.2-py3-none-any.whl (962 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.5/962.5 kB\u001b[0m \u001b[31m116.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading speechbrain-1.0.3-py3-none-any.whl (864 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 kB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hear21passt-0.0.26-py3-none-any.whl (33 kB)\n",
      "Downloading panns_inference-0.1.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading wandb-0.19.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m133.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
      "Downloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m145.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.12.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m156.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (219 kB)\n",
      "Downloading yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (333 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
      "Downloading pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m196.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
      "Downloading sentry_sdk-2.29.1-py2.py3-none-any.whl (341 kB)\n",
      "Downloading timm-1.0.15-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m164.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading huggingface_hub-0.32.3-py3-none-any.whl (512 kB)\n",
      "Downloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m181.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
      "Downloading ruamel.yaml-0.18.12-py3-none-any.whl (118 kB)\n",
      "Downloading ruamel.yaml.clib-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (722 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m722.2/722.2 kB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m204.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m168.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m160.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m167.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m136.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.6-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Downloading torchlibrosa-0.1.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: triton, sentencepiece, nvidia-cusparselt-cu12, mpmath, typing-inspection, sympy, setproctitle, sentry-sdk, safetensors, ruamel.yaml.clib, pyparsing, pydantic-core, protobuf, propcache, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, multidict, lightning-utilities, kiwisolver, hf-xet, fsspec, frozenlist, fonttools, docker-pycreds, cycler, contourpy, click, async-timeout, annotated-types, aiohappyeyeballs, yarl, ruamel.yaml, pydantic, nvidia-cusparse-cu12, nvidia-cudnn-cu12, matplotlib, huggingface_hub, aiosignal, wandb, nvidia-cusolver-cu12, hyperpyyaml, aiohttp, torchlibrosa, torch, torchvision, torchmetrics, torchaudio, panns_inference, timm, speechbrain, pytorch-lightning, lightning, hear21passt\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62/62\u001b[0m [hear21passt]\u001b[0m [lightning]ghtning]12]2]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.6 aiosignal-1.3.2 annotated-types-0.7.0 async-timeout-5.0.1 click-8.2.1 contourpy-1.3.2 cycler-0.12.1 docker-pycreds-0.4.0 fonttools-4.58.1 frozenlist-1.6.0 fsspec-2025.5.1 hear21passt-0.0.26 hf-xet-1.1.2 huggingface_hub-0.32.3 hyperpyyaml-1.2.2 kiwisolver-1.4.8 lightning-2.5.1 lightning-utilities-0.14.3 matplotlib-3.10.3 mpmath-1.3.0 multidict-6.4.4 networkx-3.4.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 panns_inference-0.1.1 pillow-11.2.1 propcache-0.3.1 protobuf-6.31.1 pydantic-2.11.5 pydantic-core-2.33.2 pyparsing-3.2.3 pytorch-lightning-2.5.1.post0 ruamel.yaml-0.18.12 ruamel.yaml.clib-0.2.12 safetensors-0.5.3 sentencepiece-0.2.0 sentry-sdk-2.29.1 setproctitle-1.3.6 speechbrain-1.0.3 sympy-1.13.1 timm-1.0.15 torch-2.6.0 torchaudio-2.6.0 torchlibrosa-0.1.0 torchmetrics-1.7.2 torchvision-0.21.0 triton-3.2.0 typing-inspection-0.4.1 wandb-0.19.11 yarl-1.20.0\n",
      "Collecting cuda-python\n",
      "  Downloading cuda_python-12.9.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting cuda-bindings~=12.9.0 (from cuda-python)\n",
      "  Downloading cuda_bindings-12.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Downloading cuda_python-12.9.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading cuda_bindings-12.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m143.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: cuda-bindings, cuda-python\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [cuda-python]s]\n",
      "\u001b[1A\u001b[2KSuccessfully installed cuda-bindings-12.9.0 cuda-python-12.9.0\n",
      "Required libraries installed.\n",
      "Setup complete. Checkpoints are expected in './resources' directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib64/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib64/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib64/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib64/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib64/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1) (1.20.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib64/python3.9/site-packages (from numba>=0.51.0->librosa==0.11.0) (0.43.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=1.1.0->librosa==0.11.0) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib64/python3.9/site-packages (from soundfile>=0.12.1->librosa==0.11.0) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa==0.11.0) (2.22)\n",
      "Requirement already satisfied: safetensors in /home/ec2-user/.local/lib/python3.9/site-packages (from timm>=0.4.12->hear21passt) (0.5.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/ec2-user/.local/lib/python3.9/site-packages (from huggingface_hub->speechbrain) (1.1.2)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.9/site-packages (from hyperpyyaml->speechbrain) (0.18.10)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib64/python3.9/site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain) (0.2.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib64/python3.9/site-packages (from jinja2->torch==2.6.0) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib64/python3.9/site-packages (from matplotlib->panns_inference) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/site-packages (from matplotlib->panns_inference) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib64/python3.9/site-packages (from matplotlib->panns_inference) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib64/python3.9/site-packages (from matplotlib->panns_inference) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/site-packages (from matplotlib->panns_inference) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/site-packages (from matplotlib->panns_inference) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/site-packages (from matplotlib->panns_inference) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->panns_inference) (3.21.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: cuda-python in /home/ec2-user/.local/lib/python3.9/site-packages (12.9.0)\n",
      "Requirement already satisfied: cuda-bindings~=12.9.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from cuda-python) (12.9.0)\n",
      "Required libraries installed.\n",
      "Setup complete. Checkpoints are expected in './resources' directory.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO: SETUP YOUR PROJECT HERE.\n",
    "\"\"\"\n",
    "\n",
    "git_clone_checkout(\n",
    "    output_dir='qvim_baseline_rp', \n",
    "    url='https://github.com/RP335/qvim-baseline', \n",
    "    branch='main', \n",
    "    commit_sha='8222f2f4651b08a7d3a47026bce6948657c7bf2e' \n",
    ")\n",
    "print(\"Cloned RP335/qvim-baseline repository.\")\n",
    "\n",
    "\n",
    "!pip install speechbrain hear21passt panns_inference wandb torchaudio==2.6.0 torch==2.6.0 lightning==2.5.1 librosa==0.11.0 torchvision==0.21.0\n",
    "!pip install cuda-python\n",
    "print(\"Required libraries installed.\")\n",
    "\n",
    "\n",
    "\n",
    "google_drive_download(filename=\"aug_baseline_latest.ckpt\", shared_url=\"https://drive.google.com/file/d/1HglQg8wTQaHzV6eSVND99hfLfUkQnLPl/view?usp=download\", relative_dir = \"resources\")\n",
    "google_drive_download(filename=\"mrr_values_baseline_mobilenet.csv\", shared_url=\"https://drive.google.com/file/d/1eFL3uYAbLJmJCNMmjvS4aus1WRu47cVH/view?usp=download\", relative_dir = \"resources\")\n",
    "google_drive_download(filename=\"passt_finetuned_1.ckpt\", shared_url=\"https://drive.google.com/file/d/1SjyHPMjyBzSuSj1cWe2NKIOM0m3VUN3k/view?usp=download\", relative_dir = \"resources\")\n",
    "google_drive_download(filename=\"Cnn14_mAP=0.431.pth\", shared_url=\"https://drive.google.com/file/d/1zbWcCrF_oopLsk4il5q6oMwl2-lfhwXT/view?usp=download\", relative_dir = \"resources\")\n",
    "google_drive_download(filename=\"panns_finetuned_2.ckpt\", shared_url=\"https://drive.google.com/file/d/10QXhEjc0bimeonr6SDBix_MBnss6e4cy/view?usp=download\", relative_dir = \"resources\")\n",
    "google_drive_download(filename=\"beats_finetuned_3.ckpt\", shared_url=\"https://drive.google.com/file/d/1ryZLXpdfn6bM9qd49FQpNQys8jW0TS2r/view?usp=download\", relative_dir = \"resources\")\n",
    "google_drive_download(filename=\"BEATs_iter3.pt\", shared_url=\"https://drive.google.com/file/d/1NmDz4TFdf66nbxe1NK5-z2I416SIg9FH/view?usp=download\", relative_dir = \"resources\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "os.makedirs(os.path.join(ROOT_PATH, \"resources\"), exist_ok=True)\n",
    "print(f\"Setup complete. Checkpoints are expected in '{os.path.join(ROOT_PATH, 'resources')}' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Implement the QVIMModel Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Prepended to sys.path for local modules: /home/ec2-user/notebooks/qvim_baseline_rp/src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported MobileNetOriginalQVIMModule and QVIMModuleAlternate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2025-06-02 11:20:31--  http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/class_labels_indices.csv\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.180.207, 172.253.115.207, 172.253.122.207, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.180.207|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14675 (14K) [application/octet-stream]\n",
      "Saving to: ‘/home/ec2-user/panns_data/class_labels_indices.csv’\n",
      "\n",
      "     0K .......... ....                                       100% 6.82M=0.002s\n",
      "\n",
      "2025-06-02 11:20:31 (6.82 MB/s) - ‘/home/ec2-user/panns_data/class_labels_indices.csv’ saved [14675/14675]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO: ADD YOUR IMPLEMENTATION HERE.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import librosa\n",
    "import argparse\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Determine the target device\n",
    "_TARGET_DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {_TARGET_DEVICE}\")\n",
    "\n",
    "PATH_TO_YOUR_REPO_SRC = os.path.abspath(os.path.join(ROOT_PATH, \"qvim_baseline_rp\", \"src\"))\n",
    "if PATH_TO_YOUR_REPO_SRC not in sys.path:\n",
    "    sys.path.insert(0, PATH_TO_YOUR_REPO_SRC)\n",
    "    print(f\"Prepended to sys.path for local modules: {PATH_TO_YOUR_REPO_SRC}\")\n",
    "\n",
    "try:\n",
    "    # Assuming ex_qvim_original.py contains the baseline QVIMModule\n",
    "    from qvim_mn_baseline.ex_qvim_original import QVIMModule as MobileNetOriginalQVIMModule\n",
    "    from qvim_mn_baseline.ex_qvim_alt import QVIMModuleAlternate # For PaSST, PANNs, BEATs\n",
    "    print(\"Successfully imported MobileNetOriginalQVIMModule and QVIMModuleAlternate.\")\n",
    "except ImportError as e:\n",
    "    print(f\"ERROR importing Lightning Modules: {e}\")\n",
    "    print(f\"Ensure your cloned repo 'qvim_baseline_rp' is in '{ROOT_PATH}', contains ex_qvim_original.py and ex_qvim_alt.py, and sys.path is correct.\")\n",
    "    raise\n",
    "\n",
    "\n",
    "# QVIMModel class definition needs to be provided if it's a custom base class.\n",
    "# Assuming it's defined elsewhere or is a placeholder for a known library's class.\n",
    "# For this example, I'll add a minimal placeholder if it's not imported.\n",
    "try:\n",
    "    QVIMModel # Check if it exists\n",
    "except NameError:\n",
    "    class QVIMModel: # Minimal placeholder\n",
    "        def __init__(self): pass\n",
    "        def embed_item(self, file_path: str) -> np.ndarray: raise NotImplementedError\n",
    "        def embed_query(self, file_path: str) -> np.ndarray: raise NotImplementedError\n",
    "        def compute_similarities(self, items: dict[str, str], queries: dict[str, str]) -> dict[str, dict[str, float]]: raise NotImplementedError\n",
    "\n",
    "\n",
    "class MobileNetV3Baseline(QVIMModel):\n",
    "    def __init__(self, checkpoint_filename=\"baseline.ckpt\", resources_dir=\"resources\"):\n",
    "        super(MobileNetV3Baseline, self).__init__()\n",
    "        self.device = _TARGET_DEVICE\n",
    "        self.config_runtime = argparse.Namespace(\n",
    "            project='qvim_baseline_eval', num_workers=0, num_gpus=(1 if self.device.type == 'cuda' else 0), model_save_path=None,\n",
    "            dataset_path='data', target_classes=[], pretrained_name='mn10_as', random_seed=None,\n",
    "            batch_size=16, n_epochs=15, weight_decay=0.0, max_lr=0.0003, min_lr=0.0001,\n",
    "            warmup_epochs=1, rampdown_epochs=7, initial_tau=0.07, tau_trainable=False,\n",
    "            duration=10.0, sample_rate=32000, window_size=800, hop_size=320, n_fft=1024,\n",
    "            n_mels=128, freqm=2, timem=200, fmin=0, fmax=(32000 // 2),\n",
    "            fmin_aug_range=10, fmax_aug_range=2000\n",
    "        )\n",
    "        checkpoint_path = os.path.join(ROOT_PATH, resources_dir, checkpoint_filename)\n",
    "        print(f\"Loading MobileNetV3 baseline from: {checkpoint_path}\")\n",
    "        if not os.path.exists(checkpoint_path):\n",
    "            checkpoint_path_alt = os.path.join(ROOT_PATH, resources_dir, \"aug_baseline_latest.ckpt\")\n",
    "            if os.path.exists(checkpoint_path_alt): checkpoint_path = checkpoint_path_alt\n",
    "            else: raise FileNotFoundError(f\"MobileNetV3 baseline checkpoint '{checkpoint_filename}' or alternates not found in '{os.path.join(ROOT_PATH, resources_dir)}'\")\n",
    "\n",
    "        try:\n",
    "            self.qvim_model = MobileNetOriginalQVIMModule.load_from_checkpoint(\n",
    "                checkpoint_path, map_location=self.device,\n",
    "                config=self.config_runtime, strict=False\n",
    "            )\n",
    "        except Exception as e_load:\n",
    "            print(f\"Direct load_from_checkpoint failed for MobileNetV3: {e_load}. Attempting manual state_dict load.\")\n",
    "            self.qvim_model = MobileNetOriginalQVIMModule(config=self.config_runtime)\n",
    "            try: ckpt_data = torch.load(checkpoint_path, map_location=self.device, weights_only=True)\n",
    "            except: ckpt_data = torch.load(checkpoint_path, map_location=self.device, weights_only=False)\n",
    "\n",
    "            state_dict_to_load = ckpt_data.get('state_dict', ckpt_data)\n",
    "            self.qvim_model.load_state_dict(state_dict_to_load, strict=False)\n",
    "            if not hasattr(self.qvim_model, 'config'): self.qvim_model.config = self.config_runtime\n",
    "\n",
    "        self.qvim_model = self.qvim_model.eval().to(self.device)\n",
    "        self.config_for_audio_loading = self.qvim_model.config\n",
    "        print(f\"MobileNetV3 model ready on device: {self.device}\")\n",
    "\n",
    "    def load_audio(self, file_path: str) -> torch.Tensor:\n",
    "        audio, _ = librosa.load(file_path, sr=self.config_for_audio_loading.sample_rate, mono=True, duration=self.config_for_audio_loading.duration)\n",
    "        fixed_length = int(self.config_for_audio_loading.sample_rate * self.config_for_audio_loading.duration)\n",
    "        array = np.zeros(fixed_length, dtype=np.float32)\n",
    "        current_len = len(audio)\n",
    "        if current_len < fixed_length: array[:current_len] = audio\n",
    "        else: array = audio[:fixed_length].astype(np.float32)\n",
    "        return torch.from_numpy(array).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def embed_item(self, file_path: str) -> np.ndarray:\n",
    "        with torch.no_grad(): return self.qvim_model.forward_reference(self.load_audio(file_path)).detach().cpu().numpy().squeeze()\n",
    "    def embed_query(self, file_path: str) -> np.ndarray:\n",
    "        with torch.no_grad(): return self.qvim_model.forward_imitation(self.load_audio(file_path)).detach().cpu().numpy().squeeze()\n",
    "\n",
    "    def compute_similarities(self, items: dict[str, str], queries: dict[str, str]) -> dict[str, dict[str, float]]:\n",
    "        scores = {q_id: {} for q_id in queries.keys()}\n",
    "        if not items or not queries: return scores\n",
    "        item_embs = {item_id: self.embed_item(item_path) for item_id, item_path in tqdm(items.items(), desc=\"Embedding Items (MobileNetV3)\")}\n",
    "        query_embs = {query_id: self.embed_query(query_path) for query_id, query_path in tqdm(queries.items(), desc=\"Embedding Queries (MobileNetV3)\")}\n",
    "        for q_name, q_emb in tqdm(query_embs.items(), desc=\"Calculating Similarities (MobileNetV3)\"):\n",
    "            for i_name, i_emb in item_embs.items():\n",
    "                scores[q_name][i_name] = float(np.dot(i_emb.flatten(), q_emb.flatten()))\n",
    "        return scores\n",
    "\n",
    "class FineTunedModelWrapper(QVIMModel):\n",
    "    def __init__(self,\n",
    "                 finetuned_checkpoint_filename: str,\n",
    "                 model_type_name: str,\n",
    "                 config_for_qvima_init: argparse.Namespace,\n",
    "                 resources_dir=\"resources\"):\n",
    "        super(FineTunedModelWrapper, self).__init__()\n",
    "        self.device = _TARGET_DEVICE\n",
    "        self.model_type_name = model_type_name\n",
    "        self.config_runtime_for_qvima = config_for_qvima_init\n",
    "\n",
    "        actual_finetuned_checkpoint_path = os.path.join(ROOT_PATH, resources_dir, finetuned_checkpoint_filename)\n",
    "        if not os.path.exists(actual_finetuned_checkpoint_path):\n",
    "            raise FileNotFoundError(f\"{model_type_name} fine-tuned checkpoint '{finetuned_checkpoint_filename}' not found in '{os.path.join(ROOT_PATH, resources_dir)}'\")\n",
    "\n",
    "        print(f\"Loading {model_type_name} fine-tuned model from: {actual_finetuned_checkpoint_path}\")\n",
    "\n",
    "        if not hasattr(self.config_runtime_for_qvima, 'model_type') or self.config_runtime_for_qvima.model_type != self.model_type_name:\n",
    "            print(f\"Warning: Forcing model_type in config_for_qvima_init for {model_type_name} to '{self.model_type_name}'. Original: {getattr(self.config_runtime_for_qvima, 'model_type', 'None')}\")\n",
    "        self.config_runtime_for_qvima.model_type = self.model_type_name\n",
    "        self.config_runtime_for_qvima.num_gpus = (1 if self.device.type == 'cuda' else 0)\n",
    "\n",
    "        if self.model_type_name == \"passt\":\n",
    "            try: from hear21passt.base import load_model as passt_loader_check # noqa\n",
    "            except ImportError: raise ImportError(\"hear21passt library required for PaSST model but not found.\")\n",
    "        elif self.model_type_name == \"panns\":\n",
    "            try: from panns_inference import AudioTagging as PannsModelCheck # noqa\n",
    "            except ImportError: raise ImportError(\"panns_inference library required for PANNs model but not found.\")\n",
    "        elif self.model_type_name == \"beats\":\n",
    "            try: from speechbrain.lobes.models.beats import BEATs as SpeechBrainBEATsModel_check # noqa\n",
    "            except ImportError: raise ImportError(\"SpeechBrain library required for BEATs model but not found.\")\n",
    "\n",
    "        print(f\"Initializing QVIMModuleAlternate for {self.model_type_name} with effective config:\")\n",
    "\n",
    "        self.qvim_alternate_model = QVIMModuleAlternate.load_from_checkpoint(\n",
    "            checkpoint_path=actual_finetuned_checkpoint_path,\n",
    "            map_location=self.device,\n",
    "            config=self.config_runtime_for_qvima,\n",
    "            strict=False\n",
    "        )\n",
    "        self.qvim_alternate_model = self.qvim_alternate_model.eval().to(self.device)\n",
    "        self.config_for_audio_loading = self.qvim_alternate_model.hparams\n",
    "        print(f\"{model_type_name} model ready on device: {self.device}\")\n",
    "\n",
    "    def load_audio(self, file_path: str) -> torch.Tensor:\n",
    "        audio, _ = librosa.load(file_path, sr=self.config_for_audio_loading.sample_rate, mono=True, duration=self.config_for_audio_loading.duration)\n",
    "        fixed_length = int(self.config_for_audio_loading.sample_rate * self.config_for_audio_loading.duration)\n",
    "        array = np.zeros(fixed_length, dtype=np.float32)\n",
    "        current_len = len(audio)\n",
    "        if current_len < fixed_length: array[:current_len] = audio\n",
    "        else: array = audio[:fixed_length].astype(np.float32)\n",
    "        return torch.from_numpy(array).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def embed_item(self, file_path: str) -> np.ndarray:\n",
    "        with torch.no_grad(): return self.qvim_alternate_model.forward_reference(self.load_audio(file_path)).detach().cpu().numpy().squeeze()\n",
    "    def embed_query(self, file_path: str) -> np.ndarray:\n",
    "        with torch.no_grad(): return self.qvim_alternate_model.forward_imitation(self.load_audio(file_path)).detach().cpu().numpy().squeeze()\n",
    "\n",
    "    def compute_similarities(self, items: dict[str, str], queries: dict[str, str]) -> dict[str, dict[str, float]]:\n",
    "        scores = {q_id: {} for q_id in queries.keys()}\n",
    "        if not items or not queries: return scores\n",
    "        item_embs = {item_id: self.embed_item(item_path) for item_id, item_path in tqdm(items.items(), desc=f\"Embedding Items ({self.model_type_name})\")}\n",
    "        query_embs = {query_id: self.embed_query(query_path) for query_id, query_path in tqdm(queries.items(), desc=f\"Embedding Queries ({self.model_type_name})\")}\n",
    "        for q_name, q_emb in tqdm(query_embs.items(), desc=f\"Calculating Similarities ({self.model_type_name})\"):\n",
    "            for i_name, i_emb in item_embs.items():\n",
    "                if q_emb is not None and i_emb is not None and q_emb.size > 0 and i_emb.size > 0:\n",
    "                    scores[q_name][i_name] = float(np.dot(i_emb.flatten(), q_emb.flatten()))\n",
    "                else:\n",
    "                    scores[q_name][i_name] = -float('inf')\n",
    "        return scores\n",
    "\n",
    "\n",
    "class FusionEnsembleModel(QVIMModel):\n",
    "    def __init__(self,\n",
    "                 model_wrappers: dict,\n",
    "                 fusion_strategy: str = \"weighted_average_scores\",\n",
    "                 global_model_weights: dict = None,\n",
    "                 rrf_k: int = 60\n",
    "                 ):\n",
    "        super(FusionEnsembleModel, self).__init__()\n",
    "        self.model_wrappers = model_wrappers\n",
    "        self.fusion_strategy = fusion_strategy\n",
    "        self.device = _TARGET_DEVICE\n",
    "\n",
    "        self.global_model_weights = global_model_weights if global_model_weights else {}\n",
    "        self.normalized_global_weights = {}\n",
    "        if self.model_wrappers:\n",
    "            active_weights = {name: self.global_model_weights.get(name, 1.0) for name in self.model_wrappers.keys()}\n",
    "            total_weight = sum(active_weights.values())\n",
    "            if total_weight > 0:\n",
    "                self.normalized_global_weights = {name: weight / total_weight for name, weight in active_weights.items()}\n",
    "            else:\n",
    "                num_m = len(self.model_wrappers)\n",
    "                self.normalized_global_weights = {name: 1.0 / num_m if num_m > 0 else 0 for name in self.model_wrappers.keys()}\n",
    "        \n",
    "        if self.fusion_strategy == \"weighted_average_scores\":\n",
    "            print(f\"  Normalized global weights for 'weighted_average_scores': {self.normalized_global_weights}\")\n",
    "\n",
    "        self.rrf_k = rrf_k\n",
    "\n",
    "        print(f\"\\nFusionEnsembleModel initialized:\")\n",
    "        print(f\"  Models: {list(self.model_wrappers.keys())}\")\n",
    "        print(f\"  Fusion strategy: {self.fusion_strategy}\")\n",
    "\n",
    "\n",
    "    def _get_single_model_embeddings(self, file_path: str, embed_method_name: str, model_name: str) -> np.ndarray:\n",
    "        model_wrapper = self.model_wrappers.get(model_name)\n",
    "        if not model_wrapper: return np.array([])\n",
    "        if embed_method_name == \"item\": return model_wrapper.embed_item(file_path)\n",
    "        elif embed_method_name == \"query\": return model_wrapper.embed_query(file_path)\n",
    "        raise ValueError(f\"Invalid embed_method_name: {embed_method_name}\")\n",
    "\n",
    "    def _get_concatenated_embeddings(self, file_path: str, embed_method_name: str) -> np.ndarray:\n",
    "        all_embeddings_list = []\n",
    "        model_order = [\"mobilenet\", \"panns\", \"passt\", \"beats\"]\n",
    "        for model_name in model_order:\n",
    "            if model_name in self.model_wrappers:\n",
    "                emb = self._get_single_model_embeddings(file_path, embed_method_name, model_name)\n",
    "                if emb.size > 0: all_embeddings_list.append(emb.flatten())\n",
    "        if not all_embeddings_list: return np.array([])\n",
    "        return np.concatenate(all_embeddings_list)\n",
    "\n",
    "    def embed_item(self, file_path: str) -> np.ndarray:\n",
    "        if self.fusion_strategy == \"embedding_concat\":\n",
    "            return self._get_concatenated_embeddings(file_path, \"item\")\n",
    "        raise NotImplementedError(\"Direct embed_item on FusionEnsembleModel is for 'embedding_concat'. Call on individual wrappers or use 'embedding_concat' strategy.\")\n",
    "\n",
    "    def embed_query(self, file_path: str) -> np.ndarray:\n",
    "        if self.fusion_strategy == \"embedding_concat\":\n",
    "            return self._get_concatenated_embeddings(file_path, \"query\")\n",
    "        raise NotImplementedError(\"Direct embed_query on FusionEnsembleModel is for 'embedding_concat'. Call on individual wrappers or use 'embedding_concat' strategy.\")\n",
    "\n",
    "\n",
    "    def compute_similarities(self, items: dict[str, str], queries: dict[str, str]) -> dict[str, dict[str, float]]:\n",
    "        final_scores = {query_id: {} for query_id in queries.keys()}\n",
    "        if not self.model_wrappers or not items or not queries: return final_scores\n",
    "\n",
    "        if self.fusion_strategy == \"embedding_concat\":\n",
    "            print(f\"\\nFusionEnsembleModel: Using '{self.fusion_strategy}'.\")\n",
    "            item_embs_fused = {item_id: self._get_concatenated_embeddings(item_path, \"item\")\n",
    "                               for item_id, item_path in tqdm(items.items(), desc=\"Items (Concat)\")}\n",
    "            query_embs_fused = {query_id: self._get_concatenated_embeddings(query_path, \"query\")\n",
    "                                for query_id, query_path in tqdm(queries.items(), desc=\"Queries (Concat)\")}\n",
    "            for query_id, q_emb_fused in tqdm(query_embs_fused.items(), desc=\"Similarities (Concat)\"):\n",
    "                for item_id, i_emb_fused in item_embs_fused.items():\n",
    "                    if q_emb_fused.size > 0 and i_emb_fused.size > 0:\n",
    "                        final_scores[query_id][item_id] = float(np.dot(i_emb_fused.flatten(), q_emb_fused.flatten()))\n",
    "                    else: final_scores[query_id][item_id] = -float('inf')\n",
    "            return final_scores\n",
    "\n",
    "        all_item_embeddings = {name: {} for name in self.model_wrappers.keys()}\n",
    "        all_query_embeddings = {name: {} for name in self.model_wrappers.keys()}\n",
    "        print(\"\\nFusionEnsembleModel: Pre-calculating all individual model embeddings...\")\n",
    "        for model_name, model_wrapper in self.model_wrappers.items():\n",
    "            print(f\"  Embedding items with {model_name}...\")\n",
    "            all_item_embeddings[model_name] = {item_id: model_wrapper.embed_item(item_path)\n",
    "                                               for item_id, item_path in tqdm(items.items(), desc=f\"Items ({model_name})\")}\n",
    "            print(f\"  Embedding queries with {model_name}...\")\n",
    "            all_query_embeddings[model_name] = {query_id: model_wrapper.embed_query(query_path)\n",
    "                                                for query_id, query_path in tqdm(queries.items(), desc=f\"Queries ({model_name})\")}\n",
    "\n",
    "        print(f\"\\nFusionEnsembleModel: Applying '{self.fusion_strategy}' fusion...\")\n",
    "\n",
    "        if self.fusion_strategy == \"rrf\":\n",
    "            all_model_ranks_for_query = {qid: {} for qid in queries.keys()}\n",
    "            for query_id in tqdm(queries.keys(), desc=\"RRF: Generating Ranks\"):\n",
    "                for model_name in self.model_wrappers.keys():\n",
    "                    q_emb = all_query_embeddings[model_name].get(query_id)\n",
    "                    if q_emb is None or q_emb.size == 0: continue\n",
    "                    current_model_item_scores = {\n",
    "                        item_id: np.dot(i_emb.flatten(), q_emb.flatten())\n",
    "                        for item_id, i_emb in all_item_embeddings[model_name].items()\n",
    "                        if i_emb is not None and i_emb.size > 0\n",
    "                    }\n",
    "                    if not current_model_item_scores: continue\n",
    "                    sorted_items = sorted(current_model_item_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "                    all_model_ranks_for_query[query_id][model_name] = {item_id: rank for rank, (item_id, _) in enumerate(sorted_items)}\n",
    "\n",
    "            for query_id in tqdm(queries.keys(), desc=\"RRF: Fusing Ranks\"):\n",
    "                for item_id in items.keys():\n",
    "                    rrf_score_val = 0.0\n",
    "                    for model_name in self.model_wrappers.keys():\n",
    "                        rank = all_model_ranks_for_query.get(query_id, {}).get(model_name, {}).get(item_id)\n",
    "                        if rank is not None: rrf_score_val += 1.0 / (self.rrf_k + rank)\n",
    "                    final_scores[query_id][item_id] = float(rrf_score_val)\n",
    "            return final_scores\n",
    "\n",
    "        elif self.fusion_strategy == \"weighted_average_scores\":\n",
    "            for query_id in tqdm(queries.keys(), desc=f\"Fusing Scores ({self.fusion_strategy})\"):\n",
    "                for item_id in items.keys():\n",
    "                    fused_score = -float('inf')\n",
    "                    scores_from_models_list = []\n",
    "                    weights_for_scores_list = []\n",
    "                    \n",
    "                    active_weights_source = self.normalized_global_weights\n",
    "\n",
    "                    for model_name in self.model_wrappers.keys():\n",
    "                        # Ensure model has a global weight assigned; if not, it won't contribute\n",
    "                        model_global_weight = active_weights_source.get(model_name)\n",
    "                        if model_global_weight is None or model_global_weight == 0:\n",
    "                            continue\n",
    "\n",
    "                        q_emb = all_query_embeddings[model_name].get(query_id)\n",
    "                        i_emb = all_item_embeddings[model_name].get(item_id)\n",
    "                        if q_emb is not None and i_emb is not None and q_emb.size > 0 and i_emb.size > 0:\n",
    "                            sim = np.dot(i_emb.flatten(), q_emb.flatten())\n",
    "                            scores_from_models_list.append(sim)\n",
    "                            weights_for_scores_list.append(model_global_weight)\n",
    "\n",
    "                    if scores_from_models_list:\n",
    "                        sum_effective_weights = sum(weights_for_scores_list)\n",
    "                        if sum_effective_weights > 1e-9:\n",
    "                            normalized_effective_weights = [w / sum_effective_weights for w in weights_for_scores_list]\n",
    "                            fused_score = np.sum(np.array(scores_from_models_list) * np.array(normalized_effective_weights))\n",
    "                        elif scores_from_models_list: \n",
    "                            fused_score = np.mean(scores_from_models_list)\n",
    "                    \n",
    "                    final_scores[query_id][item_id] = float(fused_score)\n",
    "            return final_scores\n",
    "            \n",
    "        else:\n",
    "            raise NotImplementedError(f\"Fusion strategy '{self.fusion_strategy}' is not supported. Must be 'embedding_concat', 'rrf', or 'weighted_average_scores'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Create an Instance of your QVIMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device for initial checkpoint data loading (e.g., hparams): cuda\n",
      "\n",
      "Instantiating individual model wrappers...\n",
      "Loading MobileNetV3 baseline from: ./resources/aug_baseline_latest.ckpt\n",
      "Could not instantiate MobileNetV3Baseline: MobileNetV3 baseline checkpoint 'aug_baseline_latest.ckpt' or alternates not found in './resources'\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_3599/3744478250.py\", line 29, in <module>\n",
      "    mobilenet_wrapper = MobileNetV3Baseline(checkpoint_filename=MOBILENET_CKPT_FILENAME, resources_dir=RESOURCES_DIR)\n",
      "  File \"/tmp/ipykernel_3599/3563947200.py\", line 65, in __init__\n",
      "    else: raise FileNotFoundError(f\"MobileNetV3 baseline checkpoint '{checkpoint_filename}' or alternates not found in '{os.path.join(ROOT_PATH, resources_dir)}'\")\n",
      "FileNotFoundError: MobileNetV3 baseline checkpoint 'aug_baseline_latest.ckpt' or alternates not found in './resources'\n",
      "\n",
      "Fine-tuned PaSST ckpt not found at ./resources/passt_finetuned_1.ckpt, skipping.\n",
      "Fine-tuned PANNs ckpt not found at ./resources/panns_finetuned_2.ckpt, skipping.\n",
      "Fine-tuned BEATs ckpt not found at ./resources/beats_finetuned_3.ckpt, skipping.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CRITICAL: No models were successfully instantiated. Cannot proceed with fusion.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 87\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beats_wrapper: models_to_fuse[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeats\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m beats_wrapper\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m models_to_fuse:\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRITICAL: No models were successfully instantiated. Cannot proceed with fusion.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModels available for fusion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(models_to_fuse\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     90\u001b[0m global_ensemble_weights \u001b[38;5;241m=\u001b[39m { \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmobilenet\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.45\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpanns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.10\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpasst\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.20\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeats\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.25\u001b[39m }\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CRITICAL: No models were successfully instantiated. Cannot proceed with fusion."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beats model ready on device: cuda\n",
      "FineTunedModelWrapper for BEATs instantiated.\n",
      "\n",
      "Models available for fusion: ['mobilenet', 'passt', 'panns', 'beats']\n",
      "\n",
      "Instantiating FusionEnsembleModel with strategy: class_hybrid_best_or_softmax_weighted_avg\n",
      "\n",
      "FusionEnsembleModel initialized:\n",
      "  Models: ['mobilenet', 'passt', 'panns', 'beats']\n",
      "  Fusion strategy: class_hybrid_best_or_softmax_weighted_avg\n",
      "  Strong baseline model: mobilenet\n",
      "FusionEnsembleModel instantiated as QBVIM_MODEL.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO: INSTANTIATE YOUR MODEL HERE.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import argparse\n",
    "from glob import glob\n",
    "import torch \n",
    "import traceback\n",
    "\n",
    "_DEVICE_FOR_INIT_LOAD = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device for initial checkpoint data loading (e.g., hparams): {_DEVICE_FOR_INIT_LOAD}\")\n",
    "\n",
    "\n",
    "RESOURCES_DIR = \"resources\"\n",
    "MOBILENET_CKPT_FILENAME = \"aug_baseline_latest.ckpt\"\n",
    "FINETUNED_PASST_CKPT_FILENAME = \"passt_finetuned_1.ckpt\"\n",
    "FINETUNED_PANNS_CKPT_FILENAME = \"panns_finetuned_2.ckpt\"\n",
    "FINETUNED_BEATS_CKPT_FILENAME = \"beats_finetuned_3.ckpt\"\n",
    "ORIGINAL_BEATS_ITER3_CKPT_PATH_FOR_INIT = os.path.join(ROOT_PATH, RESOURCES_DIR, \"BEATs_iter3.pt\")\n",
    "ORIGINAL_PANNS_CNN14_CKPT_PATH_FOR_INIT = os.path.join(ROOT_PATH, RESOURCES_DIR, \"Cnn14_mAP=0.431.pth\")\n",
    "\n",
    "\n",
    "print(\"\\nInstantiating individual model wrappers...\")\n",
    "mobilenet_wrapper, passt_wrapper, panns_wrapper, beats_wrapper = None, None, None, None\n",
    "\n",
    "try:\n",
    "    mobilenet_wrapper = MobileNetV3Baseline(checkpoint_filename=MOBILENET_CKPT_FILENAME, resources_dir=RESOURCES_DIR)\n",
    "    print(\"MobileNetV3Baseline instantiated.\")\n",
    "except Exception as e: print(f\"Could not instantiate MobileNetV3Baseline: {e}\\n{traceback.format_exc()}\")\n",
    "\n",
    "try:\n",
    "    passt_ft_ckpt_path = os.path.join(ROOT_PATH, RESOURCES_DIR, FINETUNED_PASST_CKPT_FILENAME)\n",
    "    if os.path.exists(passt_ft_ckpt_path):\n",
    "        passt_ckpt_data = torch.load(passt_ft_ckpt_path, map_location=_DEVICE_FOR_INIT_LOAD)\n",
    "        hparams_passt = passt_ckpt_data.get(\"hyper_parameters\", passt_ckpt_data.get(\"hparams\", {}))\n",
    "        config_passt_runtime = argparse.Namespace(**hparams_passt) if isinstance(hparams_passt, dict) else hparams_passt\n",
    "        config_passt_runtime.model_type = \"passt\"\n",
    "        config_passt_runtime.passt_input_type = getattr(config_passt_runtime, 'passt_input_type', 'raw')\n",
    "\n",
    "        passt_wrapper = FineTunedModelWrapper(FINETUNED_PASST_CKPT_FILENAME, \"passt\", config_passt_runtime, RESOURCES_DIR)\n",
    "        print(\"FineTunedModelWrapper for PaSST instantiated.\")\n",
    "    else: print(f\"Fine-tuned PaSST ckpt not found at {passt_ft_ckpt_path}, skipping.\")\n",
    "except Exception as e: print(f\"Could not instantiate PaSST wrapper: {e}\\n{traceback.format_exc()}\")\n",
    "\n",
    "try:\n",
    "    panns_ft_ckpt_path = os.path.join(ROOT_PATH, RESOURCES_DIR, FINETUNED_PANNS_CKPT_FILENAME)\n",
    "    if os.path.exists(panns_ft_ckpt_path):\n",
    "        panns_ckpt_data = torch.load(panns_ft_ckpt_path, map_location=_DEVICE_FOR_INIT_LOAD)\n",
    "        hparams_panns = panns_ckpt_data.get(\"hyper_parameters\", panns_ckpt_data.get(\"hparams\", {}))\n",
    "        config_panns_runtime = argparse.Namespace(**hparams_panns) if isinstance(hparams_panns, dict) else hparams_panns\n",
    "        config_panns_runtime.model_type = \"panns\"\n",
    "        config_panns_runtime.panns_input_type = getattr(config_panns_runtime, 'panns_input_type', 'raw')\n",
    "        config_panns_runtime.panns_checkpoint_path = ORIGINAL_PANNS_CNN14_CKPT_PATH_FOR_INIT\n",
    "        if not os.path.exists(config_panns_runtime.panns_checkpoint_path): print(f\"Warning: Original PANNs Cnn14 ckpt not found at '{config_panns_runtime.panns_checkpoint_path}'.\")\n",
    "\n",
    "        panns_wrapper = FineTunedModelWrapper(FINETUNED_PANNS_CKPT_FILENAME, \"panns\", config_panns_runtime, RESOURCES_DIR)\n",
    "        print(\"FineTunedModelWrapper for PANNs instantiated.\")\n",
    "    else: print(f\"Fine-tuned PANNs ckpt not found at {panns_ft_ckpt_path}, skipping.\")\n",
    "except Exception as e: print(f\"Could not instantiate PANNs wrapper: {e}\\n{traceback.format_exc()}\")\n",
    "\n",
    "try:\n",
    "    beats_ft_ckpt_path = os.path.join(ROOT_PATH, RESOURCES_DIR, FINETUNED_BEATS_CKPT_FILENAME)\n",
    "    if os.path.exists(beats_ft_ckpt_path):\n",
    "        beats_ckpt_data = torch.load(beats_ft_ckpt_path, map_location=_DEVICE_FOR_INIT_LOAD)\n",
    "        hparams_beats = beats_ckpt_data.get(\"hyper_parameters\", beats_ckpt_data.get(\"hparams\", {}))\n",
    "        config_beats_runtime = argparse.Namespace(**hparams_beats) if isinstance(hparams_beats, dict) else hparams_beats\n",
    "        config_beats_runtime.model_type = \"beats\"\n",
    "        config_beats_runtime.beats_checkpoint_path = ORIGINAL_BEATS_ITER3_CKPT_PATH_FOR_INIT\n",
    "        if not os.path.exists(config_beats_runtime.beats_checkpoint_path): print(f\"Warning: Original BEATs iter3 ckpt not found at '{config_beats_runtime.beats_checkpoint_path}'.\")\n",
    "        config_beats_runtime.beats_savedir = getattr(config_beats_runtime, 'beats_savedir', os.path.join(ROOT_PATH, \"pretrained_models_cache\", \"beats_submission\"))\n",
    "\n",
    "        beats_wrapper = FineTunedModelWrapper(FINETUNED_BEATS_CKPT_FILENAME, \"beats\", config_beats_runtime, RESOURCES_DIR)\n",
    "        print(\"FineTunedModelWrapper for BEATs instantiated.\")\n",
    "    else: print(f\"Fine-tuned BEATs ckpt not found at {beats_ft_ckpt_path}, skipping.\")\n",
    "except Exception as e: print(f\"Could not instantiate BEATs wrapper: {e}\\n{traceback.format_exc()}\")\n",
    "\n",
    "\n",
    "models_to_fuse = {}\n",
    "if mobilenet_wrapper: models_to_fuse[\"mobilenet\"] = mobilenet_wrapper\n",
    "if passt_wrapper: models_to_fuse[\"passt\"] = passt_wrapper\n",
    "if panns_wrapper: models_to_fuse[\"panns\"] = panns_wrapper\n",
    "if beats_wrapper: models_to_fuse[\"beats\"] = beats_wrapper\n",
    "\n",
    "if not models_to_fuse:\n",
    "    raise RuntimeError(\"CRITICAL: No models were successfully instantiated. Cannot proceed with fusion.\")\n",
    "print(f\"\\nModels available for fusion: {list(models_to_fuse.keys())}\")\n",
    "\n",
    "global_ensemble_weights = { \"mobilenet\": 0.45, \"panns\": 0.10, \"passt\": 0.20, \"beats\": 0.25 }\n",
    "active_global_weights = {name: weight for name, weight in global_ensemble_weights.items() if name in models_to_fuse}\n",
    "\n",
    "\n",
    "# CHOOSE FUSION STRATEGY: \"weighted_average_scores\", \"rrf\", or \"embedding_concat\"\n",
    "CHOSEN_FUSION_STRATEGY = \"weighted_average_scores\" \n",
    "# Or CHOSEN_FUSION_STRATEGY = \"rrf\"\n",
    "# Or CHOSEN_FUSION_STRATEGY = \"embedding_concat\"\n",
    "\n",
    "\n",
    "print(f\"\\nInstantiating FusionEnsembleModel with strategy: {CHOSEN_FUSION_STRATEGY}\")\n",
    "QBVIM_MODEL = FusionEnsembleModel(\n",
    "    model_wrappers=models_to_fuse,\n",
    "    fusion_strategy=CHOSEN_FUSION_STRATEGY,\n",
    "    global_model_weights=active_global_weights,\n",
    "    rrf_k=60 # rrf_k is still relevant if \"rrf\" strategy is chosen\n",
    ")\n",
    "print(\"FusionEnsembleModel instantiated as QBVIM_MODEL.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dICiJ1tOm4Vh"
   },
   "source": [
    "## Create Predictions\n",
    "\n",
    "To run this, download the development dataset and store them in `DATA_PATH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flFJzBKtX2cw"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DO NOT MODIFY THIS BLOCK.\n",
    "\"\"\"\n",
    "from glob import glob\n",
    "\n",
    "items_path = os.path.join(DATA_PATH, \"Items\")\n",
    "item_files = pd.DataFrame({'path': list(glob(os.path.join(items_path, \"**\", \"*.wav\"), recursive=True))})\n",
    "item_files[\"Class\"] = item_files['path'].transform(lambda x: x.split(os.path.sep)[-2])\n",
    "item_files[\"Items\"] = item_files['path'].transform(lambda x: x.split(os.path.sep)[-1])\n",
    "\n",
    "queries_path = os.path.join(DATA_PATH, \"Queries\")\n",
    "query_files = pd.DataFrame({'path': list(glob(os.path.join(queries_path, \"**\", \"*.wav\"), recursive=True))})\n",
    "query_files[\"Class\"] = query_files['path'].transform(lambda x: x.split(os.path.sep)[-2])\n",
    "query_files[\"Query\"] = query_files['path'].transform(lambda x: x.split(os.path.sep)[-1])\n",
    "\n",
    "print(\"Total item files:\", len(item_files))\n",
    "print(\"Total query files:\", len(query_files))\n",
    "\n",
    "if len(query_files) == 0 or len(item_files) == 0:\n",
    "    raise ValueError(\"No query files found! Download the development dataset and store it in 'DATA_PATH'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing Scores (class_hybrid_best_or_softmax_weighted_avg): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1021/1021 [00:00<00:00, 1067.38it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DO NOT MODIFY THIS BLOCK.\n",
    "\"\"\"\n",
    "\n",
    "scores = QBVIM_MODEL.compute_similarities(\n",
    "    items = {row[\"Items\"]: row[\"path\"] for i, row in item_files.iterrows()},\n",
    "    queries = {row[\"Query\"]: row[\"path\"] for i, row in query_files.iterrows()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T01:11:13.229554Z",
     "start_time": "2025-04-05T01:11:13.087740Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DO NOT MODIFY THIS BLOCK.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "os.makedirs(os.path.join(ROOT_PATH, \"output\"), exist_ok=True)\n",
    "\n",
    "with open(os.path.join(ROOT_PATH, \"output\", \"similarities.json\"), \"w\") as f:\n",
    "    json.dump(scores, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on the Public Development Set\n",
    "\n",
    "Computes the Reciprocal Rank (RR) for each query in the public development set. The RR is the inverted rank $r_i$ of the correct item for query $i$. Submissions will be ranked via the Mean Reciprocal Randk (MRR) of queries $Q$ on a hidden test set:\n",
    "\n",
    "$$MRR = \\frac{1}{\\lvert Q \\rvert} \\sum_{i=1}^{\\lvert Q\\rvert} \\frac{1}{r_i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DO NOT MODIFY THIS BLOCK.\n",
    "\"\"\"\n",
    "import json\n",
    "\n",
    "with open(os.path.join(ROOT_PATH, \"output\", \"similarities.json\"), \"r\") as f:\n",
    "    scores = json.load(f)\n",
    "\n",
    "rankings = pd.DataFrame(dict(\n",
    "    **{ \"id\": [i for i in list(scores.keys())]},\n",
    "    **{ k: [v[k] for v in  scores.values() ] for k in scores[list(scores.keys())[0]].keys()}\n",
    ")).set_index(\"id\")\n",
    "\n",
    "df = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, \"DEVUpdateComplete.csv\"), skiprows=1\n",
    ")[['Label', 'Class', 'Items', 'Query 1', 'Query 2', 'Query 3']]\n",
    "\n",
    "df = df.melt(\n",
    "    id_vars=[col for col in df.columns if \"Query\" not in col],\n",
    "    value_vars=[\"Query 1\", \"Query 2\", \"Query 3\"],\n",
    "    var_name=\"Query Type\",\n",
    "    value_name=\"Query\"\n",
    ").dropna()\n",
    "\n",
    "# remove missing files\n",
    "rankings = rankings.loc[df[\"Query\"].unique(), df[\"Items\"].unique()]\n",
    "\n",
    "# load file with ground truth, i.e., query->item mapping; column 0 is item, colum 1 query\n",
    "ground_truth = {row['Query']: [row['Items']] for i, row in df.iterrows()}\n",
    "\n",
    "# find the rank of the correct item (real recording) for each query (imitation)\n",
    "position_of_correct = {}\n",
    "missing_query_files = []\n",
    "for query, correct_item_list in ground_truth.items():\n",
    "    # Skip if query is not in the DataFrame\n",
    "    if query not in rankings.index:\n",
    "        missing_query_files.append(query)\n",
    "        continue\n",
    "    # Get row and sort items by similarity in descending order\n",
    "    sorted_items = rankings.loc[query].sort_values(ascending=False)\n",
    "    # Find rank of correct items\n",
    "    position_of_correct[query] = {\n",
    "        item: sorted_items.index.get_loc(item) for item in correct_item_list if item in sorted_items.index\n",
    "    }\n",
    "    assert len(position_of_correct[query]) == len(correct_item_list), f\"Missing item! Got: {list(position_of_correct[query].keys())}. Expected: {correct_item_list}\"\n",
    "\n",
    "# compute MRR\n",
    "normalized_rrs = []\n",
    "for query, items_ranks in position_of_correct.items():\n",
    "    rr, irr = [], [] # summed RR and ideal RR\n",
    "    for i, (item, rank) in enumerate(items_ranks.items()):\n",
    "        rr.append(1 / (rank + 1))\n",
    "        irr.append(1 / (i + 1))\n",
    "    normalized_rrs.append(sum(rr) / sum(irr)) # normalize MRR with ideal one\n",
    "mrr = np.mean(normalized_rrs)\n",
    "\n",
    "print(\"Missing query files: \", len(missing_query_files))\n",
    "print(\"Missing item files: \", missing_query_files)\n",
    "print(\"MRR random:\", round((1/ np.arange(1,len(df[\"Items\"].unique()))).mean(), 4))\n",
    "print(\"MRR       :\", round(mrr, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DO NOT MODIFY THIS BLOCK.\n",
    "\"\"\"\n",
    "\n",
    "ground_truth = {\n",
    "    row[\"Query\"]: [row_[\"Items\"] for j, row_ in df.drop_duplicates(\"Items\").iterrows() if row_[\"Class\"] == row[\"Class\"]] for i, row in df.drop_duplicates(\"Query\").iterrows()\n",
    "}\n",
    "\n",
    "position_of_correct = {}\n",
    "missing_query_files = []\n",
    "for query, correct_item_list in ground_truth.items():\n",
    "    # Skip if query is not in the DataFrame\n",
    "    if query not in rankings.index:\n",
    "        missing_query_files.append(query)\n",
    "        continue\n",
    "    # Get row and sort items by similarity in descending order\n",
    "    sorted_items = rankings.loc[query].sort_values(ascending=False)\n",
    "    # Find rank of correct items\n",
    "    position_of_correct[query] = {item: sorted_items.index.get_loc(item) for item in correct_item_list if item in sorted_items.index}\n",
    "    assert len(position_of_correct[query]) == len(correct_item_list), f\"Missing item!\"\n",
    "\n",
    "# compute MRR\n",
    "normalized_rrs = []\n",
    "for query, items_ranks in position_of_correct.items():\n",
    "    rr, irr = [], [] # summed RR and ideal RR\n",
    "    for i, (item, rank) in enumerate(items_ranks.items()):\n",
    "        rr.append(1 / (rank + 1))\n",
    "        irr.append(1 / (i + 1))\n",
    "    normalized_rrs.append(sum(rr) / sum(irr)) # normalize MRR with ideal one\n",
    "mrr = np.mean(normalized_rrs)\n",
    "\n",
    "# compute NDCG\n",
    "normalized_dcg = []\n",
    "ndcgs = {}\n",
    "for query, items_ranks in position_of_correct.items():\n",
    "    dcg, idcg = [], [] # summed RR and ideal RR\n",
    "    for i, (item, rank) in enumerate(items_ranks.items()):\n",
    "        dcg.append(1 / np.log2(rank + 2))\n",
    "        idcg.append(1 / np.log2(i + 2))\n",
    "    normalized_dcg.append(sum(dcg) / sum(idcg)) # normalize MRR with ideal one\n",
    "    ndcgs[query] = sum(dcg) / sum(idcg)\n",
    "ndcg = np.mean(normalized_dcg)\n",
    "\n",
    "print(\"Class-wise MRR :\", round(mrr, 4))\n",
    "print(\"Class-wise NDCG:\", round(ndcg, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
